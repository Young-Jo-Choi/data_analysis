summary(na.omit(air$Ozone))
boxplot(na.omit(air$Ozone))
boxplot(na.omit(air$Ozone),horizontal = T)
View(air)
View(baseball)
boxplopt(Sepal.Width~Species, iris)
boxplot(Sepal.Width~Species, iris)
boxplot(Sepal.Width~Species, iris)
OzoneBP <- boxplot(Sepal.Width~Species, iris)
OzoneBP
boxplot(na.omit(air$Ozone),horizontal = T)
boxplot(Sepal.Width~Species, iris)
Sys.Date()
as.Date('2021,5,5')
as.Date('2021-5-
5')
as.Date('2021-5-5')
Sys.time()
as.POSIXct(2)
as.POSIXct(2,origin="2021-08-01")
as.POSIXct(2,origin="2021-08-01-18")
as.POSIXct("2021-08-1-18")
as.POSIXct("2021-08-1 18")
as.POSIXct("2021-08-1 18:00")
as.POSIXct(2,origin="2021-08-01 18:00")
time <- as.POSIXlt(Sys.Date())
time
time$year
time$year + 1900
time$month
time$mon
time$mon+1
time$mday
time$wday
format(time, '%y-%m:%d')
Sys.Date+365
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
Sys.Date()+365
idx <- sample(1:nrow(iris), nrow(iris)*0.7, replace = F)
training <-iris[idx,]
test <- iris[-idx,]
install.packages("sampling")
library(sampling)
sample <- strata(data = iris, c("Species"), size = c(20,15,15), method = 'srswor')
table(sample$Species)
sample
iris_sample <- getdata(iris,sample)
iris_sample
rm(list = ls())
library(MASS)
str(cats)
df <- as.data.frame(cats)
head(df)
table(df$Sex)
shapiro.test(df$Bwt)
# 정규분포를 만족하지 않으므로 shapiro wil
mean(df$Bwt
)
wilcox.test(cats$Bwt, mu=2.6,alternative = 'two.sided')
wilcox.test(cats$Bwt, mu=2.7,alternative = 'two.sided')
before = c(7,3,4,5,2,1,6,6,5,4)
after = c(8,4,5,6,2,3,6,8,6,5)
t.test(before, after, alternative = 'less',paired=T)
t.test(before, after, alternative = 'two.sided',paired=T)
# 독립표본 T-검정 : 두 개의 독립된 모집단의 평균을 비교
# 두 모집단이 정규성 만족해야, 두 모집단이 등분산 가정을 만족해야
# 예시) 귀무가설 - 고양이들의 성별에 따른 평균 몸무게에는 통계적으로 유의한 차이가 없다.
var.test(Bwt~Sex, data=cats)
t.test(Bwt~Sex, data = cats, alternative='two.sided', var.equal = F)
# 적합성 검정 : 관측값들이 예상한 이론과 일치하는지 아닌지를 검정
# (모집단 분포에 대한 가정이 옳게 됐는지를 관측 자료와 비교하여 검정)
# 귀무가설 : 실제 분포와 이론적 분포간 차이가 없다.
data(survey, package="MASS")
str(survey)
table(survey$W.Hnd)
data<-table(survey$W.Hnd)
# 귀무가설 - 왼손잡이가 20%, 오른손잡이가 80%이다.
chisq.test(data, p=c(0.2,0.8))
# 독립성 검정 : 모집단을 범주화하는 기주의 되는 두 변수 A,B가
# 서로 독립적으로 관측값에 영향을 미치는가 여부 검정
# 귀무가설 : 두 변수 사이에는 연관이 없다.(독립이다)
table(survey$W.Hnd, survey$Exer)
# 독립성 검정 : 모집단을 범주화하는 기주의 되는 두 변수 A,B가
# 서로 독립적으로 관측값에 영향을 미치는가 여부 검정
# 귀무가설 : 두 변수 사이에는 연관이 없다.(독립이다)
using.table <- table(survey$W.Hnd, survey$Exer)
chisq.test(using.table)
data(iris)
result <- aov(Sepal.Width~ Species, data=iris)
result
summary(result)
# 사후검정 : 어떤 종들 간 평균 차이가 있는지 파악
TukeyHSD(result)
data('mtcars')
str(mtcars)
# aov함수 사용시 그룹을 구분하는 기준 변수는 반드시 팩터형
mtcars$cyl <- as.factor(mtcars$cyl)
mtcars$am <- as.factor(mtcars$am)
car <- mtcars[,c('cyl','am','mpg')]
str(car)
car_aov <- aov(mpg~cyl*am ,car)
summary(car_aov)
interaction.plot(car$cyl, car$am, car$mpg, col = c('red','blue'))
library(MASS)
data("Cars93")
Cars93_lm <- lm(Price~EngineSize, data=Cars93)
summary(Cars93_lm)
par(mfrow=c(2,3))
plot(Cars93_lm,which=c(1:6))
set.seed(1234)
idx<-sample(1:nrow(Cars93),5)
idx
test <- Cars93[idx,]
predict.lm(Cars93_lm,test,interval="none")
test
predict.lm(Cars93_lm,test$EngineSize,interval="none")
predict.lm(Cars93_lm,test,interval=0.95)
predict.lm(Cars93_lm,test,interval="0.95")
predict.lm(Cars93_lm,test,interval="confidence")
# newdata는 data.frame 형태로 넣어야
predict.lm(Cars93_lm,test,interval="none")
predict.lm(Cars93_lm,test,interval="prediction")
library(MASS)
data("Cars93")
# 인자나 기능이 헷갈리면 help를 통해 도움 받을 수 있다.
x = Cars93$Length
y = Cars93$Weight
plot(x, y, xlab='Length',ylab='Weight', main='Cars93')
dev.new()
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400))
dev.new()
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400),pch=8)
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400),pch=8)
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400),pch='*')
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400),cex=0.5)
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400),cex=2)
plot(x, y, xlab='Length',ylab='Weight', main='Cars93',xlim=c(130,230),ylim=c(1600,4400),cex=2,col='blue')
# plot 함수 그래프의 종류(type) : p(점), l(선), b(점과 선을 모두), o(점과 선 중첩), n(그래프 초기화)
tapply(x, y, mean)
# plot 함수 그래프의 종류(type) : p(점), l(선), b(점과 선을 모두), o(점과 선 중첩), n(그래프 초기화)
temp_obj <- tapply(x, y, mean)
type(temp_obj)
class(temp_obj)
# plot 함수 그래프의 종류(type) : p(점), l(선), b(점과 선을 모두), o(점과 선 중첩), n(그래프 초기화)
temp_obj <- tapply(y, x, mean)
class(temp_obj)
temp_array
temp_obj
unique(x)
length(unique(x))
length(temp_obj)
plot(temp_obj, xlab='Length', ylab='Weigth', type='p')
plot(temp_obj, xlab='Length', ylab='Weigth', type='l')
plot(temp_obj, xlab='Length', ylab='Weigth', type='b')
plot(temp_obj, xlab='Length', ylab='Weigth', type='o')
# 선그래프(l)에 대한 종류(lty)
plot(temp_obj, xlab='Length', ylab='Weigth', type='l', lty=4)
# 서식
plot(1:10, type='n', xlab="",ylab="")
legend("bottom",c("x1","x2"),pch=1:2,title="bottom legend")
legend("bottom",c("x1","x2"),pch=1,title="bottom legend")
legend("bottom",c("x1","x2"),pch=3:4,title="bottom legend")
# 서식
plot(1:10, type='n', xlab="",ylab="")
legend("bottom",c("x1","x2"),pch=3:4,title="bottom legend")
# 서식
plot(1:10, type='n', xlab="",ylab="")
legend("bottom",c("x1","x2"),pch=1,title="bottom legend")
# pch에 벡터 형태로 넣음으로써 여러 모양 표현 가능
legend("bottom",c("x1","x2"),pch=1:2,title="bottom legend",bg='gray')
legend(7.5,4,c("x3","x4"),pch=5:6,lty=7:8,title='사용자 지정')
# 서식
plot(1:10, type='n', xlab="",ylab="")
# pch에 벡터 형태로 넣음으로써 여러 모양 표현 가능
legend("bottom",c("x1","x2"),pch=5:6,title="bottom legend",bg='gray')
legend(7.5,4,c("x3","x4"),pch=1:2,lty=7:8,title='사용자 지정')
plot(NULL, type='n',xlim=c(0,8),ylim=c(0,3),xlab='Petal.Length',ylab='Petal.Width',main='iris')
points(iris$Sepal.Length, iris$Petal.Width, cex=0.5)
points(iris$Petal.Length, iris$Petal.Width, cex=0.5)
# 선 그래프
plot(NULL, type='n',xlim=c(0,20),ylim=c(0,20),main='선 그래프')
lines(c(0,17),c(17,17),lty=1)
sep(0,12,2)
sep(0,12,2)
seq(0,12,2)
lty_vec <- c(1,2,3,'solid','dotdash','twodash','longdash')
lty_vec <- list(1,2,3,'solid','dotdash','twodash','longdash')
View(lty_vec)
lty_vec(1)
lty_vec[[1]]
lty_vec[[2]]
lty_vec[[6]]
lty_list <- list(1,2,3,'solid','dotdash','twodash','longdash')
lwd_list <- list(NULL,NULL,NULL,NULL,1,2,3,4)
for(i in c(1:7)){
lines(c(0,19-i*2),c(17,17),lty=lty_list[[i]],lwd=lwd_list[[i]])
}
# 선 그래프
plot(NULL, type='n',xlim=c(0,20),ylim=c(0,20),main='선 그래프')
for(i in c(1:7)){
lines(c(0,19-i*2),c(19-i*2,19-i*2),lty=lty_list[[i]],lwd=lwd_list[[i]])
}
?lines
data(cars)
cars_df <- as.data.frame(cars)
View(cars_df)
plot(cars_df, main = "Stopping distance versus Speed")
lowess(cars_df)
lines(lowess(cars_df))
# 직선 그래프(abline)
plot(cars_df, ylim=c(0,130),xlim=c(0,30),main='cars data')
cars_lm <- lm(dist~speed, data=cars)
abline(cars_lm,col='red')
abline(v=median(cars$speed), lty=3)
abline(h=median(cars_df$dist), lty=3)
# 곡선 그래프(curve)
?dnorm
dnorm(x,mean=0,sd=1)
dnorm(0,mean=0,sd=1)
curve(dnorm(x,mean=0,sd=1),from=-3, to=3, xlab="x", ylab="density", main="curve of dnorm")
abine(dnorm(x,mean=0,sd=1),from=-3, to=3, xlab="x", ylab="density", main="curve of dnorm")
abline(dnorm(x,mean=0,sd=1),from=-3, to=3, xlab="x", ylab="density", main="curve of dnorm")
curve(dnorm(x,mean=0,sd=1),from=-3, to=3, xlab="x", ylab="density", main="curve of dnorm")
# 막대 그래프(barplot)
table(Cars93$Origin)
# 막대 그래프(barplot)
barplot(table(Cars93$Origin),ylim=c(1,50),xlab="Origin",ylab="도수")
# 막대 그래프(barplot)
barplot(table(Cars93$Cylinders),ylim=c(1,55),xlab="Cylinders",ylab="도수")
barplot(table(Cars93$Origin, Cars93$Cylinders),beside=F,ylim=c(0,60),legend=T)
barplot(table(Cars93$Origin, Cars93$Cylinders),beside=T,ylim=c(0,60),legend=T) # 여러 범주
table(Cars93$Origin, Cars93$Cylinders)
table(Cars93$Origin)
table(Cars93$Cylinders)
# 히스토그램
hist(iris$Petal.Length)
# 히스토그램
hist(iris$Petal.Length, breaks=5)
# 히스토그램(hist) : breaks 인자 통해 구간의 개수 정하거나 임의의 구간을 벡터로 지정 가능
hist(iris$Petal.Length, breaks=5, freq=T)
# 히스토그램(hist) : breaks 인자 통해 구간의 개수 정하거나 임의의 구간을 벡터로 지정 가능
hist(iris$Petal.Length, breaks=5, freq=F)
# 히스토그램(hist) : breaks 인자 통해 구간의 개수 정하거나 임의의 구간을 벡터로 지정 가능
hist(iris$Petal.Length, breaks=5)
# 파이 차트
pie(table(Cars93$Cylinders))
# 파이 차트
pie(table(Cars93$Cylinders),labels=c("first","second","third","fourth","fifth","sixth"))
# 산점도 행렬(pairs) : 행렬,데이터프레임과 같이 데이터를 입력하는 방식 / formula를 입력하는 방식
pairs(~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=iris,
col=c("red","green","blue")[iris$Species],
pch=c('+','*','#')[iris$Species])
legend(unique(iris$Species))
legend(0.85, 0.7, as.vector(unique(iris$Species)),
fill=c("red", "green3", "blue"))
legend("bottom", as.vector(unique(iris$Species)),
fill=c("red", "green3", "blue"))
# 산점도 행렬(pairs) : 행렬,데이터프레임과 같이 데이터를 입력하는 방식 / formula를 입력하는 방식
pairs(~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=iris,
col=c("red","green","blue")[iris$Species],
pch=c('+','*','#')[iris$Species])
legend("bottom", as.vector(unique(iris$Species)))
par(xpd=TRUE)
legend("bottom", as.vector(unique(iris$Species)),fill=c("red", "green3", "blue"))
legend(0.85, 0.7, as.vector(unique(iris$Species)),fill=c("red", "green3", "blue"))
# 산점도 행렬(pairs) : 행렬,데이터프레임과 같이 데이터를 입력하는 방식 / formula를 입력하는 방식
pairs(~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=iris,
col=c("red","green","blue")[iris$Species],
pch=c('+','*','#')[iris$Species])
par(xpd=TRUE)
legend(0.85, 0.7, as.vector(unique(iris$Species)),fill=c("red", "green3", "blue"))
legend(0.85, 0.7, as.vector(unique(iris$Species)),fill=c("red", "green3", "blue"))
# 산점도 행렬(pairs) : 행렬,데이터프레임과 같이 데이터를 입력하는 방식 / formula를 입력하는 방식
pairs(~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=iris,
col=c("red","green","blue")[iris$Species],
pch=c('+','*','#')[iris$Species])
par(xpd=TRUE)
legend("top", as.vector(unique(iris$Species)),fill=c("red", "green3", "blue"))
# 산점도 행렬(pairs) : 행렬,데이터프레임과 같이 데이터를 입력하는 방식 / formula를 입력하는 방식
pairs(~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=iris,
col=c("red","green","blue")[iris$Species],
pch=c('+','*','#')[iris$Species])
par(xpd=TRUE)
legend("bottom", as.vector(unique(iris$Species)),fill=c("red", "green3", "blue"))
rm(list=ls())
# 회귀 분석
# 선형회귀분석의 가정
# 1. 독립변수와 종속변수 간의 선형성
# 2. 오차의 등분산성, 독립성, 정규성
library(MASS)
data("Cars93")
Cars93_lm <- lm(Price~EngineSize, data=Cars93)
summary(Cars93_lm)
# 다중선형회귀분석
# 검토사항 : 데이터가 전제하는 가정을 만족시키는가, 모형 내 회귀계수가 유의한가, 설명력, 통계적 유의성,
#            모형이 데이터를 잘 적합하는가, 다중공선성(VIF : 허용오차의 역수, 10이상이면 심각하다고 판단)
# 범주형 독립변수는 일반적으로 dummy variable로 변환해 처리한다.
# lm함수는 자동으로 범주형 변수를dummy variable로 변환
iris_lm <- lm(Petal.Length~Sepal.Length+Sepal.Width+Petal.Width+Species, data=iris)
summary(iris_lm)
Price_lm <- lm(Price~EngineSize+RPM+Weight,data=Cars93)
summary(Price_lm)
# backward selection(후진제거법)
lm_b <- lm(Price~EngineSize+RPM+Length,data=Cars93)
summary(lm_b)
# backward selection(후진제거법)
lm_a <- lm(Price~EngineSize+RPM+Width+Length,data=Cars93)
summary(lm_a)
summary(Price_lm)
# 유의확률이 가장 높은 변수(Width) 제거
lm_b <- lm(Price~EngineSize+RPM+Length,data=Cars93)
summary(lm_b)
# 유의확률이 가장 높은 변수(Length) 제거
lm_c <- lm(Price~EngineSize+RPM,data=Cars93)
summary(lm_c)
# 자동으로 변수 선택해주는 함수(step)
lm_result <- lm(Price~EngineSize+Horsepower+RPM+Width+Length+Weigth,data=Cars93)
# 자동으로 변수 선택해주는 함수(step)
lm_result <- lm(Price~EngineSize+Horsepower+RPM+Width+Length+Weight,data=Cars93)
step(lm_result, direction="backward",k=2) # k=2이면 AIC 사용
rm(list=ls())
install.packages('adabag')
library(adabag)
path = 'C:/Users/hp/Desktop/최영조/코딩공부/data_analysis_exercise/ADP'
setwd(path)
credit <- read.csv('credit_final.csv')
idx <- sample(1:nrow(credit),nrow(credit)*0.7,replace = F)
train <- credit[idx,]
test <- credit[-idx,]
bag <- bagging(crdit.rating~.,data=train.mfinal=15)
bag <- bagging(crdit.rating~.,data=train,
mfinal=15) # 반복 또는 트리의 수는 15
bag <- bagging(crdit.rating~.,data=train,
mfinal=15) # 반복 또는 트리의 수는 15
bag <- bagging(credit.rating~.,data=train,
mfinal=15) # 반복 또는 트리의 수는 15
bag <- bagging(credit.rating~.,
data=train)    # 반복 또는 트리의 수는 15
View(train)
credit <- read.csv('credit_final.csv')
idx <- sample(1:nrow(credit),nrow(credit)*0.7,replace=F)
train <- credit[idx,]
test <- credit[-idx,]
library(adabag)
bag <- bagging(credit.rating~.,
data=train,
mfinal=15)    # 반복 또는 트리의 수는 15
credit$credit.rating
bag <- bagging(as.factor(credit.rating)~.,
data=train,
mfinal=15)    # 반복 또는 트리의 수는 15
credit$credit.rating <- as.factor(credit.rating)
credit$credit.rating <- as.factor(credit$credit.rating)
bag <- bagging(credit.rating~.,
data=train,
mfinal=15)    # 반복 또는 트리의 수는
logistic <- glm(credit.rating~., data=train, family='binomial') # family는 분석에 따른 link function
rm(list=ls())
library(rpart)
library(rpart.plot)
credit <- read.csv('credit_final.csv')
idx <- sample(1:nrow(credit),nrow(credit)*0.7,replace=F)
train <- credit[idx,]
test <- credit[-idx,]
dt.model <- rpart(credit.rating~.,
method='class',      # method takes one of tree types
data=train,
control = rpart.control(maxdepth=5,     # max depth
minsplit=15))   # samples of each node are at least 15
dt.model <- rpart(credit.rating~.,
method='class',      # method takes one of tree types
data=train,
control = rpart.control(maxdepth=5,     # max depth
minsplit=15))   # samples of each node are at least 15
bag <- bagging(credit.rating~.,
data=train,
mfinal=15)    # 반복 또는 트리의 수는 15
bag <- bagging(credit.rating~.,
data=credit,
mfinal=15)    # 반복 또는 트리의 수는 15
dt.model <- rpart(credit.rating~.,
method='class',      # method takes one of tree types
data=train,
control = rpart.control(maxdepth=5,     # max depth
minsplit=15))   # samples of each node are at least 15
prp(dt.model, type=4, extra=2) # plot의 인자와 같음
credit$credit.rating <- as.factor(credit$credit.rating)
bag <- bagging(credit.rating~.,
data=train,
mfinal=15)    # 반복 또는 트리의 수는 15
credit$credit.rating
names(bag)
credit <- read.csv('credit_final.csv')
credit$credit.rating <- as.factor(credit$credit.rating)
idx <- sample(1:nrow(credit),nrow(credit)*0.7,replace=F)
train <- credit[idx,]
test <- credit[-idx,]
library(adabag)
bag <- bagging(credit.rating~.,
data=train,
mfinal=15)    # 반복 또는 트리의 수는 15
names(bag)
bag$importance
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
sort(bag$importance,decreasing = T)
bag.trees <- bag$trees
View(bag.trees)
bag.trees[[1]]
bag.trees[[2]]
library(caret)
pred.bag <- predict(bag,test,type='class')
confusionMatrix(data=as.factor(pred.bg$class), reference=test$credit.rating, positive='1')
confusionMatrix(data=as.factor(pred.bag$class), reference=test$credit.rating, positive='1')
library(ROCR)
pred.bag.roc <- prediction(as.numeric(pred.bag$class),as.numeric(test[,1]))
plot(perfomance(pred.bag.roc,'tpr','fpr'))
plot(performance(pred.bag.roc,'tpr','fpr'))
abline(a=0,b=1,lty=2,col='black')
performance(pred.bag.roc, 'auc')@y.values
library(adabag)
boost <- boosting(credit.rating~.data=train,
boos=T,      # 샘플의 가중치 여부, False의 경우 모든 관측치에 동일한 가중치 부여
mfinal=80)
names(boost)
boost <- boosting(credit.rating~.data=train,
boos=T,      # 샘플의 가중치 여부, False의 경우 모든 관측치에 동일한 가중치 부여
mfinal=80)
boost <- boosting(credit.rating~.,data=train,
boos=T,      # 샘플의 가중치 여부, False의 경우 모든 관측치에 동일한 가중치 부여
mfinal=80)
names(boost)
boost$importace
boost$importance
sort(boost$importance,decreasing = T)
sort(bag$importance,decreasing = T)
boost$weights
pred.boos <- predict(boost,test,type='class')
confusionMatrix(data=as.factor(pred.boos$class), reference = test$credit.rating,positive='1')
pred.boos.roc <- prediction(as.numeric(pred.boos$class), as.numeric(test[,1]))
plot(performance(pred.boos.roc,'tpr','fpr'))
abline(a=0, b=1, lty=2, col='black')
performance(pred.boos.roc,'auc')@y.values
install.packages('randomForest')
library(randomForest)
rf.model <- randomForest(credit.rating~.,
data=train,
ntree=50,       # 사용할 트리의 수
mtry=sqrt(20),  # 사용할 변수의 개수(보통 분류는 sqrt(변수 개수), 회귀는 (변수 개수)/3)
importance=T)   # 변수중요도 결과 확인
rf.model
names(rf.model)
rf.model$importance
varImPlot(rf.model)
varImpPlot(rf.model)
rf.model$predicted
pred.rf <- predict(rf.model, test[,-1],type='class')
confusionMatrix(data=pred.rf, reference=test[,1],positive='1')
pred.rf.roc <- prediction(as.numeric(pred.rf),as.numeric(test[,1]))
plot(performace(pred.rf.roc,'tpr','fpr'))
abline(a=0,b=1,lty=2,col='black')
plot(performance(pred.rf.roc,'tpr','fpr'))
abline(a=0,b=1,lty=2,col='black')
# 예시
data(iris)
idx <- sample(1:nrow(iris), nrow(iris)*0.7, replace=T)
idx <- sample(1:nrow(iris), nrow(iris)*0.7, replace=F)
train.iris <- iris[idx,]
test.iris <- iris[-idx,]
width(iris)
length(iris)
length(iris[,-1])
rf.model.iris <- randomForest(Species~.,
,data=train.iris,
ntree=50, mtry=sqrt(length(iris[,-1])),
importance=T)
pred.rf.iris <- predict(rf.model.iris, test.iris, type='class')
pred.rf.iris <- predict(rf.model.iris, test.iris[,-1], type='class')
test.iris
test.iris[,end]
confusionMatrix(data=pred.rf.iris, reference = test.iris[,"Species"])
pred.rf.iris <- predict(rf.model.iris, test.iris[-5], type='class')
confusionMatrix(data=pred.rf.iris, reference = test.iris[,"Species"])
# SVM
library(e1071)
tune.svm(credit.rating~., data=credit,
gamma=10^(-6:-1),
cost=10^(1:2))       # 6*2=12개의 조합에서 모수 조율이 이루어짐
svm.model <- svm(credit.rating~., data=train, kernel='radial', gamma=0.01, cost=10)
summary(svm.model)
library(caret)
pred.svm <- predict(svm.model, test, type='class')
confusionMatrix(data=pred.svm, reference = test[,1], positive='1')
library(ROCR)
pred.svm.roc <- prediction(as.numeric(pred.svm),as.numeric(test[,1]))
plot(performance(pred.svm.roc,'tpr','fpr'))
abline(a=0,b=1,lty=2, col='black')
performance(pred.svm.roc,'auc')@y.values
nb.model <- naiveBayes(credit.rating~., data=train,
laplace=0)    # laplace 보정여부를 물음, default는 0으로 비활성화
nb.model
table(train$credit.rating)
205/(205+495)
View(train)
pred.nb <- predict(nb.model, test[,-1], type='class')
confusionMatrix(data=pred.nb, reference=test[,1], positive='1')
pred.nb.roc <-prediction(as.numeric(pred.nb),as.numeric(test[,1]))
','fpr'))
abline(a=0,b=1,lty=2,col='black')
plot(performance(pred.nb.roc,'tpr','fpr'))
abline(a=0,b=1,lty=2,col='black')
performance(pred.nb.roc,'auc')@y.values
rm(list=ls())
