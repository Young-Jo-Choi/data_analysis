{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 함수들은 모두 2버전을 기반으로 작성되었다.\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우의 특징\n",
    "- 넘파이와 비슷하면서 GPU 지원\n",
    "- 분산 컴퓨팅을 지원\n",
    "- JIT(just-in-time) 컴파일러를 포함. 속도를 높이고 메모리 사용량을 줄이기 위해 계산을 최적화한다.<br>\n",
    "    파이썬에서 계산 그래프를 추출한 뒤 최적화하고 효율적으로 실행\n",
    "- 계산 그래프는 플랫폼에 중립적인 포맷으로 내보낼 수 있다. 다른 환경에서 다른 환경으로 보내는 것이 가능<br>\n",
    "    예) 리눅스의 파이썬 -> 안드로이드 장치의 자바\n",
    "- 자동미분, 고성능 옵티마이저 등을 제공해 손실 함수를 쉽게 최소화할 수 있다.\n",
    "\n",
    "많은 연산은 커널(kernel)이라 부르는 여러 구현을 가지는데 각 커널은 CPU, GPU, TPU(텐서 처리 장치)와 같은 특정 장치에 맞게 만들어졌다. GPU는 계산을 작은 단위로 나누어 여러 GPU 스레드에서 병렬로 실행하므로 속도가 매우 빠르다. TPU는 딥러닝 연산을 위해 특별히 설계된 ASIC 칩이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이와 유사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 연산\n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor = tf.constant([[1.,2.,3.],[4.,5.,6.]])\n",
    "temp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(temp_tensor.shape)\n",
    "print(temp_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱싱도 유사\n",
    "temp_tensor[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor[...,1,tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실수와의 사칙연산, tf.square(tensor), tensor1 @ tf.transpose(tensor2) 등이 가능 (@는 행렬 곱셈=tf.matmul)<br>\n",
    "넘파이에서 볼 수 있는 대부분의 연산을 제공\n",
    "\n",
    "이름이 약간 다른 함수도 있음. tf.reduce_mean 와 np.mean / tf.reduce_sum 와 np.sum / tf.reduce_max 와 np.max / tf.math.log 와 np.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쉽게 변환\n",
    "a = np.array([2.,4.,5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([42., 36.], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타입 변환, 32비트, 64비트, 실수, 정수 등 다른 타입은 연산이 안됨. 필요할 경우 cast함수 사용\n",
    "tf.cast(tf.constant([42,36]),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[1.0522785 , 0.26026496],\n",
       "       [0.53359574, 0.38319394]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수 :  tf.Tensor는 변경이 불가능하지만 다음과 같이 tf.Variable로 정의하면 역전파에 의해 변경이 가능하다.\n",
    "v = tf.Variable(tf.random.normal(shape=(2,2)))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[2.104557 , 0.5205299],\n",
       "       [1.0671915, 0.7663879]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign() 메서드로 변수값 변경 가능\n",
    "v.assign(2*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[ 2.104557 , 42.       ],\n",
      "       [ 1.0671915,  0.7663879]], dtype=float32)>\n",
      "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[2.104557 , 0.       ],\n",
      "       [1.0671915, 1.       ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(v[0,1].assign(42))  # 특정 원소만 값 변경\n",
    "print(v[:,1].assign([0.,1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[100.       ,   0.       ],\n",
       "       [  1.0671915, 200.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0,0],[1,1]],updates=[100,200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 데이터 구조\n",
    "- sparse tensor (tf.SparseTensor)\n",
    "- tensor array (tf.TensorArray) : 텐서의 리스트\n",
    "- ragged tensor(tf.RaggedTensor) : 리스트의 리스트\n",
    "- string tensor : 문자열 텐서\n",
    "- 집합\n",
    "- 큐 : FIFO Queue, PriorityQueue, RandomShuffleQueue, PaddingQueue 등 (tf.queue 패키지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우로 사용자 정의 모델과 훈련 알고리즘을 만드는 것은 일단 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 함수와 그래프\n",
    "1버전에 비해 사용하기가 매우 편해졌다.<br>\n",
    "tf.function(*일반 함수)와 같은 방식으로 사용할 수 있으나 다음과 같이 사용하는 것도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=27>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x**3\n",
    "# 그래프가 생성됨\n",
    "tf_cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 파이썬 함수가 필요할 때\n",
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 사용하면 파이썬 함수를 자동으로 텐서플로우 함수로 바꿔준다. 그렇게 못하게 하려면 사용자 정의 층이나 모델 생성시 dynamic=True로 지정하거나 compile() 메서드에 run_eagerly=True로 지정하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
